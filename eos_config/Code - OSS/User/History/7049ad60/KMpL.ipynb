{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    "def pre_process(doc):\n",
    "    \"\"\"\n",
    "    pre-processes a doc\n",
    "      * Converts the tweet into lower case,\n",
    "      * removes the URLs,\n",
    "      * removes the punctuations\n",
    "      * tokenizes the tweet\n",
    "      * removes words less that 3 characters\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    # getting rid of non ascii codes\n",
    "    doc = remove_non_ascii(doc)\n",
    "    \n",
    "    # replacing URLs\n",
    "    url_pattern = \"http://[^\\s]+|https://[^\\s]+|www.[^\\s]+|[^\\s]+\\.com|bit.ly/[^\\s]+\"\n",
    "    doc = re.sub(url_pattern, 'url', doc) \n",
    "\n",
    "    # removing dollars and usernames and other unnecessary stuff\n",
    "    userdoll_pattern = \"\\$[^\\s]+|\\@[^\\s]+|\\&[^\\s]+|\\*[^\\s]+|[0-9][^\\s]+|\\~[^\\s]+\"\n",
    "    doc = re.sub(userdoll_pattern, '', doc)\n",
    "    \n",
    "    \n",
    "    # removing punctuation\n",
    "    punctuation = r\"\\(|\\)|#|\\'|\\\"|-|:|\\\\|\\/|!|\\?|_|,|=|;|>|<|\\.|\\@\"\n",
    "    doc = re.sub(punctuation, ' ', doc)\n",
    "    \n",
    "    return [w for w in doc.split() if len(w) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_termdoc(docs, vocab=[]):\n",
    "    \"\"\"\n",
    "    Construct a term-by-document-matrix\n",
    "    \n",
    "    docs: corpus\n",
    "    vocab: pre-defined vocabulary\n",
    "           if not supplied it will be automatically induced from the data\n",
    "    \n",
    "    returns the term-by-document matrix and the vocabulary of the passed corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    # vocab is not passed\n",
    "    if vocab == []:\n",
    "        vocab = set()\n",
    "        termdoc_sparse = []\n",
    "\n",
    "        for doc in docs:       \n",
    "            # computes the frequencies of doc\n",
    "            doc_sparse = Counter(doc)    \n",
    "            termdoc_sparse.append(doc_sparse)\n",
    "            \n",
    "            # update the vocab\n",
    "            vocab.update(doc_sparse.keys())  \n",
    "\n",
    "        vocab = list(vocab)\n",
    "        vocab.sort()\n",
    "    \n",
    "    else:\n",
    "        termdoc_sparse = []        \n",
    "        for doc in docs:\n",
    "            termdoc_sparse.append(Counter(doc))\n",
    "            \n",
    "\n",
    "    n_docs = len(docs)\n",
    "    n_vocab = len(vocab)\n",
    "    termdoc_dense = np.zeros((n_docs, n_vocab), dtype=int)\n",
    "\n",
    "    for j, doc_sparse in enumerate(termdoc_sparse):\n",
    "        for term, freq in doc_sparse.items():\n",
    "            try:\n",
    "                termdoc_dense[j, vocab.index(term)] = freq\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return termdoc_dense, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "\n",
    "def Euclidean_distance(x,y):\n",
    "    '''\n",
    "    Compute and return the Euclidean distance between two vectors x and y\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "    dist = (np.array(x) - np.array(y))*(np.array(x) - np.array(y))\n",
    "    return np.sqrt(dist.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "def cosine_distance(x,y):\n",
    "    '''\n",
    "    Compute and return the cosine distance between two vectors x and y\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "    num = (x * y).sum()\n",
    "    denom = np.sqrt((x * x).sum()) * np.sqrt((y * y).sum())\n",
    "    num += 0.0    # or use np.astype(float) to make sure of float division\n",
    "    return 1.0 - num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "'''\n",
    "The function takes the termdoc matrix as the input and computes variables called \"euclidean_distance_matrix\" \n",
    "and \"cosine_distance_matrix\", which are matrices whose elements (i,j) store the Eulidean distance \n",
    "and the cosine distance between tweet i-th and i-jth.\n",
    "\n",
    "Hint: you should store the distance matrices in numpy arrays for easier implementation in subsequent tasks\n",
    "'''\n",
    "\n",
    "def compute_distance_matrices(termdoc):\n",
    "    # INSERT YOUR CODE HERE\n",
    "    n_rows = termdoc.shape[0]\n",
    "    euclidean_distance = np.zeros((n_rows,n_rows))\n",
    "    cosine_distance_matrix = np.zeros((n_rows,n_rows))\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_rows):\n",
    "            euclidean_distance[i,j] = Euclidean_distance(termdoc[i,:],termdoc[j,:])\n",
    "            cosine_distance_matrix[i,j] = cosine_distance(termdoc[i,:],termdoc[j,:])\n",
    "    return euclidean_distance,cosine_distance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezikham/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[8,1],[0,0],[2,7]])\n",
    "kmeans = KMeans(3)\n",
    "kmeans.fit(x)\n",
    "print(kmeans.predict(np.array([[3,4]])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[1,2],[6,3],[3,7],[10,4]])\n",
    "Y_train = np.array([1,3,2,4])\n",
    "X_test = np.array([[6,8],[10,4]])\n",
    "knn = neighbors.KNeighborsClassifier(1)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_test = knn.predict(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.6\n"
     ]
    }
   ],
   "source": [
    "y = 11.3*9 - 47.1\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector Space Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|index|   vocab   |doc1|doc2|doc3|\n",
    "|:---:|-----------|:--:|:--:|:--:|\n",
    "|  1  |   goal    |  1 |  0 |  0 |\n",
    "|  2  |   data    |  1 |  2 |  2 |\n",
    "|  3  |information|  2 |  2 |  2 |\n",
    "|  4  |  insight  |  1 |  0 |  0 |\n",
    "|  5  |    you    |  0 |  2 |  2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The goal is to turn data into information and information into insight.',\n",
       " 'You can have data without information, but you cannot have information without data.',\n",
       " 'You can have data without information, but can you have information without data?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['goal', 'data', 'information', 'insight', 'you']\n",
    "doc1 = 'The goal is to turn data into information and information into insight.'\n",
    "doc2 = 'You can have data without information, but you cannot have information without data.'\n",
    "doc3 = 'You can have data without information, but can you have information without data?'\n",
    "doc = []\n",
    "doc.append(doc1)\n",
    "doc.append(doc2)\n",
    "doc.append(doc3)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processed =[]\n",
    "for i in range(len(doc)):\n",
    "  doc_processed.append(pre_process(doc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_termdoc, doc_vocab = construct_termdoc(doc_processed, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_termdoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goal', 'data', 'information', 'insight', 'you']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 0],\n",
       "       [0, 2, 2, 0, 2],\n",
       "       [0, 2, 2, 0, 2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_termdoc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0, y: 0\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 0, y: 1\n",
      "Euclidean: 2.6457513110645907\n",
      "\n",
      "x: 0, y: 2\n",
      "Euclidean: 2.6457513110645907\n",
      "\n",
      "x: 1, y: 0\n",
      "Euclidean: 2.6457513110645907\n",
      "\n",
      "x: 1, y: 1\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 1, y: 2\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 2, y: 0\n",
      "Euclidean: 2.6457513110645907\n",
      "\n",
      "x: 2, y: 1\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 2, y: 2\n",
      "Euclidean: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_rows = doc_termdoc.shape[0]\n",
    "for i in range(n_rows):\n",
    "  for j in range(n_rows):\n",
    "    print(\"x: {}, y: {}\".format(i,j))\n",
    "    print('Euclidean: {}'.format(Euclidean_distance(doc_termdoc[i,:],doc_termdoc[j,:])))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0, y: 0\n",
      "Cosine: 1.1102230246251565e-16\n",
      "\n",
      "x: 0, y: 1\n",
      "Cosine: 0.3453463292920228\n",
      "\n",
      "x: 0, y: 2\n",
      "Cosine: 0.3453463292920228\n",
      "\n",
      "x: 1, y: 0\n",
      "Cosine: 0.3453463292920228\n",
      "\n",
      "x: 1, y: 1\n",
      "Cosine: -2.220446049250313e-16\n",
      "\n",
      "x: 1, y: 2\n",
      "Cosine: -2.220446049250313e-16\n",
      "\n",
      "x: 2, y: 0\n",
      "Cosine: 0.3453463292920228\n",
      "\n",
      "x: 2, y: 1\n",
      "Cosine: -2.220446049250313e-16\n",
      "\n",
      "x: 2, y: 2\n",
      "Cosine: -2.220446049250313e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_rows = doc_termdoc.shape[0]\n",
    "for i in range(n_rows):\n",
    "  for j in range(n_rows):\n",
    "    print(\"x: {}, y: {}\".format(i,j))\n",
    "    print('Cosine: {}'.format(cosine_distance(doc_termdoc[i,:],doc_termdoc[j,:])))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_euc, doc_cos = compute_distance_matrices(doc_termdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.64575131, 2.64575131],\n",
       "       [2.64575131, 0.        , 0.        ],\n",
       "       [2.64575131, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11022302e-16,  3.45346329e-01,  3.45346329e-01],\n",
       "       [ 3.45346329e-01, -2.22044605e-16, -2.22044605e-16],\n",
       "       [ 3.45346329e-01, -2.22044605e-16, -2.22044605e-16]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
