{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    "def pre_process(doc):\n",
    "    \"\"\"\n",
    "    pre-processes a doc\n",
    "      * Converts the tweet into lower case,\n",
    "      * removes the URLs,\n",
    "      * removes the punctuations\n",
    "      * tokenizes the tweet\n",
    "      * removes words less that 3 characters\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    # getting rid of non ascii codes\n",
    "    doc = remove_non_ascii(doc)\n",
    "    \n",
    "    # replacing URLs\n",
    "    url_pattern = \"http://[^\\s]+|https://[^\\s]+|www.[^\\s]+|[^\\s]+\\.com|bit.ly/[^\\s]+\"\n",
    "    doc = re.sub(url_pattern, 'url', doc) \n",
    "\n",
    "    # removing dollars and usernames and other unnecessary stuff\n",
    "    userdoll_pattern = \"\\$[^\\s]+|\\@[^\\s]+|\\&[^\\s]+|\\*[^\\s]+|[0-9][^\\s]+|\\~[^\\s]+\"\n",
    "    doc = re.sub(userdoll_pattern, '', doc)\n",
    "    \n",
    "    \n",
    "    # removing punctuation\n",
    "    punctuation = r\"\\(|\\)|#|\\'|\\\"|-|:|\\\\|\\/|!|\\?|_|,|=|;|>|<|\\.|\\@\"\n",
    "    doc = re.sub(punctuation, ' ', doc)\n",
    "    \n",
    "    return [w for w in doc.split() if len(w) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_termdoc(docs, vocab=[]):\n",
    "    \"\"\"\n",
    "    Construct a term-by-document-matrix\n",
    "    \n",
    "    docs: corpus\n",
    "    vocab: pre-defined vocabulary\n",
    "           if not supplied it will be automatically induced from the data\n",
    "    \n",
    "    returns the term-by-document matrix and the vocabulary of the passed corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    # vocab is not passed\n",
    "    if vocab == []:\n",
    "        vocab = set()\n",
    "        termdoc_sparse = []\n",
    "\n",
    "        for doc in docs:       \n",
    "            # computes the frequencies of doc\n",
    "            doc_sparse = Counter(doc)    \n",
    "            termdoc_sparse.append(doc_sparse)\n",
    "            \n",
    "            # update the vocab\n",
    "            vocab.update(doc_sparse.keys())  \n",
    "\n",
    "        vocab = list(vocab)\n",
    "        vocab.sort()\n",
    "    \n",
    "    else:\n",
    "        termdoc_sparse = []        \n",
    "        for doc in docs:\n",
    "            termdoc_sparse.append(Counter(doc))\n",
    "            \n",
    "\n",
    "    n_docs = len(docs)\n",
    "    n_vocab = len(vocab)\n",
    "    termdoc_dense = np.zeros((n_docs, n_vocab), dtype=int)\n",
    "\n",
    "    for j, doc_sparse in enumerate(termdoc_sparse):\n",
    "        for term, freq in doc_sparse.items():\n",
    "            try:\n",
    "                termdoc_dense[j, vocab.index(term)] = freq\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return termdoc_dense, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "\n",
    "def Euclidean_distance(x,y):\n",
    "    '''\n",
    "    Compute and return the Euclidean distance between two vectors x and y\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "    dist = (np.array(x) - np.array(y))*(np.array(x) - np.array(y))\n",
    "    return np.sqrt(dist.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "def cosine_distance(x,y):\n",
    "    '''\n",
    "    Compute and return the cosine distance between two vectors x and y\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "    num = (x * y).sum()\n",
    "    denom = np.sqrt((x * x).sum()) * np.sqrt((y * y).sum())\n",
    "    num += 0.0    # or use np.astype(float) to make sure of float division\n",
    "    return 1.0 - num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODE IN THIS CELL\n",
    "'''\n",
    "The function takes the termdoc matrix as the input and computes variables called \"euclidean_distance_matrix\" \n",
    "and \"cosine_distance_matrix\", which are matrices whose elements (i,j) store the Eulidean distance \n",
    "and the cosine distance between tweet i-th and i-jth.\n",
    "\n",
    "Hint: you should store the distance matrices in numpy arrays for easier implementation in subsequent tasks\n",
    "'''\n",
    "\n",
    "def compute_distance_matrices(termdoc):\n",
    "    # INSERT YOUR CODE HERE\n",
    "    n_rows = termdoc.shape[0]\n",
    "    euclidean_distance = np.zeros((n_rows,n_rows))\n",
    "    cosine_distance_matrix = np.zeros((n_rows,n_rows))\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_rows):\n",
    "            euclidean_distance[i,j] = Euclidean_distance(termdoc[i,:],termdoc[j,:])\n",
    "            cosine_distance_matrix[i,j] = cosine_distance(termdoc[i,:],termdoc[j,:])\n",
    "    return euclidean_distance,cosine_distance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezikham/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[8,1],[0,0],[2,7]])\n",
    "kmeans = KMeans(3)\n",
    "kmeans.fit(x)\n",
    "print(kmeans.predict(np.array([[3,4]])))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m],[\u001b[39m10\u001b[39m,\u001b[39m3\u001b[39m]])\n\u001b[1;32m      4\u001b[0m knn \u001b[39m=\u001b[39m neighbors\u001b[39m.\u001b[39mKNeighborsClassifier(\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m knn\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m      6\u001b[0m Y_test \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(Y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:215\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:454\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 454\u001b[0m         X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    455\u001b[0m             X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    459\u001b[0m         \u001b[39m# Classification targets require a specific format\u001b[39;00m\n\u001b[1;32m    460\u001b[0m         \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1105\u001b[0m     X,\n\u001b[1;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1118\u001b[0m )\n\u001b[1;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1122\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1124\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 5]"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[2,3],[9,4],[3,7],[10,5]])\n",
    "Y_train = np.array([1,2,3,2,4])\n",
    "X_test = np.array([[6,7],[10,3]])\n",
    "knn = neighbors.KNeighborsClassifier(1)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_test = knn.predict(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.6\n"
     ]
    }
   ],
   "source": [
    "y = 11.3*9 - 47.1\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector Space Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|index|   vocab   |doc1|doc2|doc3|\n",
    "|:---:|-----------|:--:|:--:|:--:|\n",
    "|  1  |   goal    |  1 |  0 |  0 |\n",
    "|  2  |   data    |  1 |  2 |  2 |\n",
    "|  3  |information|  2 |  2 |  2 |\n",
    "|  4  |  insight  |  1 |  0 |  0 |\n",
    "|  5  |    you    |  0 |  2 |  2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The time we spent as a student is some of the best years of our lives and fun filled.',\n",
       " 'It is not much of a surprise to learn that the average student is pretty young.',\n",
       " 'College student statistics show on average a considerable chunk of this demographic work out regularly.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['student', 'college', 'average', 'summer', 'fun']\n",
    "doc1 = 'The time we spent as a student is some of the best years of our lives and fun filled.'\n",
    "doc2 = 'It is not much of a surprise to learn that the average student is pretty young.'\n",
    "doc3 = 'College student statistics show on average a considerable chunk of this demographic work out regularly.'\n",
    "doc = []\n",
    "doc.append(doc1)\n",
    "doc.append(doc2)\n",
    "doc.append(doc3)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processed =[]\n",
    "for i in range(len(doc)):\n",
    "  doc_processed.append(pre_process(doc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_termdoc, doc_vocab = construct_termdoc(doc_processed, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_termdoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student', 'college', 'average', 'summer', 'fun']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_termdoc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "x: 0, y: 0\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 0, y: 1\n",
      "Euclidean: 1.4142135623730951\n",
      "\n",
      "x: 0, y: 2\n",
      "Euclidean: 1.7320508075688772\n",
      "\n",
      "x: 1, y: 0\n",
      "Euclidean: 1.4142135623730951\n",
      "\n",
      "x: 1, y: 1\n",
      "Euclidean: 0.0\n",
      "\n",
      "x: 1, y: 2\n",
      "Euclidean: 1.0\n",
      "\n",
      "x: 2, y: 0\n",
      "Euclidean: 1.7320508075688772\n",
      "\n",
      "x: 2, y: 1\n",
      "Euclidean: 1.0\n",
      "\n",
      "x: 2, y: 2\n",
      "Euclidean: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_rows = doc_termdoc.shape[0]\n",
    "print(n_rows)\n",
    "for i in range(n_rows):\n",
    "  for j in range(n_rows):\n",
    "    print(\"x: {}, y: {}\".format(i,j))\n",
    "    print('Euclidean: {}'.format(Euclidean_distance(doc_termdoc[i,:],doc_termdoc[j,:])))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0, y: 0\n",
      "Cosine: 2.220446049250313e-16\n",
      "\n",
      "x: 0, y: 1\n",
      "Cosine: 0.5000000000000001\n",
      "\n",
      "x: 0, y: 2\n",
      "Cosine: 0.5917517095361371\n",
      "\n",
      "x: 1, y: 0\n",
      "Cosine: 0.5000000000000001\n",
      "\n",
      "x: 1, y: 1\n",
      "Cosine: 2.220446049250313e-16\n",
      "\n",
      "x: 1, y: 2\n",
      "Cosine: 0.18350341907227408\n",
      "\n",
      "x: 2, y: 0\n",
      "Cosine: 0.5917517095361371\n",
      "\n",
      "x: 2, y: 1\n",
      "Cosine: 0.18350341907227408\n",
      "\n",
      "x: 2, y: 2\n",
      "Cosine: -2.220446049250313e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_rows = doc_termdoc.shape[0]\n",
    "for i in range(n_rows):\n",
    "  for j in range(n_rows):\n",
    "    print(\"x: {}, y: {}\".format(i,j))\n",
    "    print('Cosine: {}'.format(cosine_distance(doc_termdoc[i,:],doc_termdoc[j,:])))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_euc, doc_cos = compute_distance_matrices(doc_termdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.64575131, 2.64575131],\n",
       "       [2.64575131, 0.        , 0.        ],\n",
       "       [2.64575131, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11022302e-16,  3.45346329e-01,  3.45346329e-01],\n",
       "       [ 3.45346329e-01, -2.22044605e-16, -2.22044605e-16],\n",
       "       [ 3.45346329e-01, -2.22044605e-16, -2.22044605e-16]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
